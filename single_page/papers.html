<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="">

<title>Papers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-listing/list.min.js"></script>
<script src="../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-all-papers .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-categories','listing-title','listing-subtitle','listing-date','listing-description','listing-image','listing-outputHref','listing-display-date','listing-authors',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] }],
      
      searchColumns: ["listing-title","listing-date","listing-categories","listing-href","listing-description","listing-authors","listing-publisher","listing-display-date","listing-talk"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-all-papers'] = new List('listing-all-papers', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>
<style>html{ scroll-behavior: smooth; }</style>
<script>
    
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta property="og:title" content="Papers">
<meta property="og:site-name" content="Mimansa Jaiswal">
<meta name="twitter:title" content="Papers">
<meta name="twitter:image" content="https://mimansajaiswal.github.io/single_page/images/me.jpg">
<meta name="twitter:creator" content="@MimansaJ">
<meta name="twitter:site" content="@MimansaJ">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Mimansa Jaiswal</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../single_page/updates.html" rel="" target=""><i class="bi bi-newspaper" role="img">
</i> 
 <span class="menu-text">Updates</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../single_page/papers.html" rel="" target="" aria-current="page"><i class="bi bi-pen-fill" role="img">
</i> 
 <span class="menu-text">Papers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../notes/index.html" rel="" target=""><i class="bi bi-text-indent-left" role="img">
</i> 
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../stream/index.html" rel="" target=""><i class="bi bi-cursor-text" role="img">
</i> 
 <span class="menu-text">Blurbs</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://twitter.com/MimansaJ" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text">Twitter</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../notes/index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text">Feed</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    <h5 class="quarto-listing-category-title">Categories</h5><div class="quarto-listing-category category-default"><div class="category" data-category="">All <span class="quarto-category-count">(4)</span></div><div class="category" data-category="Confounding Factors">Confounding Factors <span class="quarto-category-count">(2)</span></div><div class="category" data-category="Data Augmentation">Data Augmentation <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Data Collection">Data Collection <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Debiasing">Debiasing <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Emotion Recognition">Emotion Recognition <span class="quarto-category-count">(4)</span></div><div class="category" data-category="Empirical Analysis">Empirical Analysis <span class="quarto-category-count">(2)</span></div><div class="category" data-category="Evaluation">Evaluation <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Generalization">Generalization <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Interpretability">Interpretability <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Metric Design">Metric Design <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Model Training">Model Training <span class="quarto-category-count">(2)</span></div><div class="category" data-category="Speech and Audio">Speech and Audio <span class="quarto-category-count">(3)</span></div><div class="category" data-category="Text">Text <span class="quarto-category-count">(2)</span></div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header">
<h1 class="title display-7">Papers</h1>
<p class="author"></p>

</header>





<div class="quarto-listing quarto-listing-container-custom" id="listing-all-papers">
<br>
<div class="list quarto-listing-custom">
         <div class="papers-card quarto-post" data-index="0" data-categories="Debiasing,Emotion Recognition,Text,Model Training,Empirical Analysis,Generalization,Evaluation,Metric Design,Interpretability" data-listing-date-sort="1664582400000">
            <div class="papers-main-metadata-display-date">
               Nov 2022
            </div>
            <div class="papers-main-metadata-publisher">
               arXiv
            </div>
            <div class="papers-main-content">
               <p class="papers-main-title">
                  Human-Centered Metric Design to Promote Generalizable and Debiased Emotion Recognition
               </p>
               <p class="papers-main-display-date-publisher-in-text"><em>In
                     arXiv,
                        Nov 2022
                  </em>
               </p>
               <p class="papers-main-authors">
                  Mimansa Jaiswal, Emily Mower Provost
               </p>
                  <div class="listing-categories">
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Debiasing'); return false;">
                           Debiasing
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Emotion Recognition'); return false;">
                           Emotion Recognition
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Text'); return false;">
                           Text
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Model Training'); return false;">
                           Model Training
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Empirical Analysis'); return false;">
                           Empirical Analysis
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Generalization'); return false;">
                           Generalization
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Evaluation'); return false;">
                           Evaluation
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Metric Design'); return false;">
                           Metric Design
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Interpretability'); return false;">
                           Interpretability
                        </div>
                  </div>
                     <div class="papers-hover_content">
                        <p class="papers-back-description">
                           Metrics for emotion recognition can be challenging due to their dependence on subjective human perception. This paper proposes a template formulation that derives human-centered, automatic, optimizable evaluation metrics for emotion recognition models. The template uses model explanations and sociolinguistic wordlists and can be applied to a sample or whole dataset. The proposed metrics include generalizability and debiasing improvement, and are tested on three models, datasets and sensitive variables. The metrics correlate with the models' performance and biased representations, and can be used to train models with increased generalizability, decreased bias, or both. The template is the first to provide quantifiable metrics for training and evaluating generalizability and bias in emotion recognition models.
                        </p>
                        <div class="papers-back-links">
                           <a href="https://arxiv.org/abs/2104.08792">PDF</a>
                        </div>
                     </div>
            </div>
         </div>
         <div class="papers-card quarto-post" data-index="1" data-categories="Data Augmentation,Emotion Recognition,Speech and Audio,Empirical Analysis" data-listing-date-sort="1593561600000">
            <div class="papers-main-metadata-display-date">
               2020
            </div>
            <div class="papers-main-metadata-publisher">
               ACL-SRW
            </div>
            <div class="papers-main-content">
               <p class="papers-main-title">
                  Noise-Based Augmentation Techniques for Emotion Datasets: What do we Recommend?
               </p>
               <p class="papers-main-display-date-publisher-in-text"><em>In
                     ACL-SRW,
                        2020
                  </em>
               </p>
               <p class="papers-main-authors">
                  Mimansa Jaiswal, Emily Mower Provost
               </p>
                  <div class="listing-categories">
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Data Augmentation'); return false;">
                           Data Augmentation
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Emotion Recognition'); return false;">
                           Emotion Recognition
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Speech and Audio'); return false;">
                           Speech and Audio
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Empirical Analysis'); return false;">
                           Empirical Analysis
                        </div>
                  </div>
                     <div class="papers-hover_content">
                        <p class="papers-back-description">
                           Multiple noise-based data augmentation approaches have been proposed to counteract this challenge in other speech domains. But, unlike speech recognition and speaker verification, the underlying label of emotion data may change given the addition of noise. In this work, we propose a set of recommendations for noise-based augmentation of emotion datasets based on human and machine performance evaluation of generated realistic noisy samples using multiple categories of environmental and synthetic noise.
                        </p>
                        <div class="papers-back-links">
                           <a href="https://arxiv.org/abs/2104.08806">PDF</a>
                              <a href="https://slideslive.com/38928670/noisebased-augmentation-techniques-for-emotion-datasets-what-do-we-recommend">Talk</a>
                        </div>
                     </div>
            </div>
         </div>
         <div class="papers-card quarto-post" data-index="2" data-categories="Data Collection,Confounding Factors,Emotion Recognition,Speech and Audio" data-listing-date-sort="1588291200000">
            <div class="papers-main-metadata-display-date">
               May 2020
            </div>
            <div class="papers-main-metadata-publisher">
               LREC
            </div>
            <div class="papers-main-content">
               <p class="papers-main-title">
                  MuSE: Multimodal Stressed Emotion Dataset
               </p>
               <p class="papers-main-display-date-publisher-in-text"><em>In
                     LREC,
                        May 2020
                  </em>
               </p>
               <p class="papers-main-authors">
                  Mimansa Jaiswal, Cristian-Paul Bara, Yuanhang Luo, Rada Mihalcea, Mihai Burzo, Emily Mower Provost
               </p>
                  <div class="listing-categories">
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Data Collection'); return false;">
                           Data Collection
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Confounding Factors'); return false;">
                           Confounding Factors
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Emotion Recognition'); return false;">
                           Emotion Recognition
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Speech and Audio'); return false;">
                           Speech and Audio
                        </div>
                  </div>
                     <div class="papers-hover_content">
                        <p class="papers-back-description">
                           This paper presents a dataset, Multimodal Stressed Emotion (MuSE), to study the multimodal interplay between the presence of stress and expressions of affect. We describe the data collection protocol, the possible areas of use, and the annotations for the emotional content of the recordings.
                        </p>
                        <div class="papers-back-links">
                           <a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.187.pdf">PDF</a>
                        </div>
                     </div>
            </div>
         </div>
         <div class="papers-card quarto-post" data-index="3" data-categories="Confounding Factors,Emotion Recognition,Speech and Audio,Text,Model Training" data-listing-date-sort="1580515200000">
            <div class="papers-main-metadata-display-date">
               Feb 2020
            </div>
            <div class="papers-main-metadata-publisher">
               AAAI and NeuRIPS-W
            </div>
            <div class="papers-main-content">
               <p class="papers-main-title">
                  Privacy Enhanced Multimodal Neural Representations for Emotion Recognition
               </p>
               <p class="papers-main-display-date-publisher-in-text"><em>In
                     AAAI and NeuRIPS-W,
                        Feb 2020
                  </em>
               </p>
               <p class="papers-main-authors">
                  Mimansa Jaiswal, Emily Mower Provost
               </p>
                  <div class="listing-categories">
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Confounding Factors'); return false;">
                           Confounding Factors
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Emotion Recognition'); return false;">
                           Emotion Recognition
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Speech and Audio'); return false;">
                           Speech and Audio
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Text'); return false;">
                           Text
                        </div>
                        <div class="listing-category" onclick="window.quartoListingCategory('/papers/Model Training'); return false;">
                           Model Training
                        </div>
                  </div>
                     <div class="papers-hover_content">
                        <p class="papers-back-description">
                           This paper presents a dataset, Multimodal Stressed Emotion (MuSE), to study the multimodal interplay between the presence of stress and expressions of affect. We describe the data collection protocol, the possible areas of use, and the annotations for the emotional content of the recordings.
                        </p>
                        <div class="papers-back-links">
                           <a href="https://arxiv.org/pdf/1910.13212.pdf">PDF</a>
                        </div>
                     </div>
            </div>
         </div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>